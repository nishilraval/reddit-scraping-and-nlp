{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns,\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import svm\n",
    "import logging\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = \"The_Donald\"\n",
    "sub2 = \"Thanosdidnothingwrong\"\n",
    "\n",
    "\n",
    "url = \"https://api.pushshift.io/reddit/search/submission/?subreddit={}&size=500\"\n",
    "res = requests.get(url.format(sub1), headers = {'User-agent': 'bruhhh'}) \n",
    "json = res.json()\n",
    "\n",
    "res2 = requests.get(url.format(sub2), headers = {'User-agent': 'bruhhh'}) \n",
    "json2 = res2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['subreddit','title',\n",
    "                      'is_video',\n",
    "                      'author','gildings',\n",
    "                      'num_comments','id','score'])\n",
    "\n",
    "row=[]\n",
    "for i in range(499):\n",
    "    row.append([json['data'][i]['subreddit'],\n",
    "    json['data'][i]['title'],\n",
    "    json['data'][i]['is_video'],\n",
    "    json['data'][i]['author'],\n",
    "    json['data'][i]['gildings'],\n",
    "    json['data'][i]['num_comments'],\n",
    "    json['data'][i]['id'],json['data'][i]['score']])\n",
    "    row.append([json2['data'][i]['subreddit'],\n",
    "    json2['data'][i]['title'],\n",
    "    json2['data'][i]['is_video'],\n",
    "    json2['data'][i]['author'],\n",
    "    json2['data'][i]['gildings'],\n",
    "    json2['data'][i]['num_comments'],\n",
    "    json2['data'][i]['id'],json['data'][i]['score']])\n",
    "    \n",
    "df = pd.DataFrame(row,columns=['subreddit','title',\n",
    "                      'is_video',\n",
    "                      'author','gildings',\n",
    "                      'num_comments','id','score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>is_video</th>\n",
       "      <th>author</th>\n",
       "      <th>gildings</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>Best tweet ever!</td>\n",
       "      <td>False</td>\n",
       "      <td>awesomepossumcausem</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>ablcrb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanosdidnothingwrong</td>\n",
       "      <td>THANOS did nothing wrong, but OBAMOS is ruinin...</td>\n",
       "      <td>False</td>\n",
       "      <td>hoprobby</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>abl9pd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>MORONS at CNN fail to understand or give prope...</td>\n",
       "      <td>False</td>\n",
       "      <td>RedditAdminsSuckIt</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>ablckn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thanosdidnothingwrong</td>\n",
       "      <td>Just a literal description of an unaltered still</td>\n",
       "      <td>False</td>\n",
       "      <td>plenarypause</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>abl99v</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>IT'S MA'AM!</td>\n",
       "      <td>False</td>\n",
       "      <td>IncredibleMrE1</td>\n",
       "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>ablchw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               subreddit                                              title  \\\n",
       "0             The_Donald                                   Best tweet ever!   \n",
       "1  thanosdidnothingwrong  THANOS did nothing wrong, but OBAMOS is ruinin...   \n",
       "2             The_Donald  MORONS at CNN fail to understand or give prope...   \n",
       "3  thanosdidnothingwrong   Just a literal description of an unaltered still   \n",
       "4             The_Donald                                        IT'S MA'AM!   \n",
       "\n",
       "   is_video               author                              gildings  \\\n",
       "0     False  awesomepossumcausem  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}   \n",
       "1     False             hoprobby  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}   \n",
       "2     False   RedditAdminsSuckIt  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}   \n",
       "3     False         plenarypause  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}   \n",
       "4     False       IncredibleMrE1  {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}   \n",
       "\n",
       "   num_comments      id  score  \n",
       "0             0  ablcrb      1  \n",
       "1             0  abl9pd      1  \n",
       "2             1  ablckn      1  \n",
       "3             1  abl99v      1  \n",
       "4             1  ablchw      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "for i in range(len(df['title'])):\n",
    "    df['title'][i] = tokenizer.tokenize(regex.sub('', df['title'][i]).lower())\n",
    "for i in range(len(df['title'])):\n",
    "    df['title'][i] = [w for w in  df['title'][i] if not w in stopwords.words(\"english\")]\n",
    "    df['title'][i] = [lemmatizer.lemmatize(word) for word in df['title'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df['title'])):\n",
    "    if df.gildings[i] == {'gid_1': 0, 'gid_2': 0, 'gid_3': 0}:\n",
    "        df.gildings[i] = 0\n",
    "    else:\n",
    "         df.gildings[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-7-9036d7696e30>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-9036d7696e30>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                            ngram_range=(1, 1), max_df=1.0,\n",
    "                            min_df=1, max_features=None)\n",
    "cv.fit(\n",
    "cv.transform(titletext)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['subreddit'])):\n",
    "    if (df.loc[i,['subreddit']])==(\"The_Donald\"):\n",
    "        df.loc[i,['subreddit']] = 0\n",
    "    else:\n",
    "        df.loc[i,['subreddit']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,4]\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_\n",
    "\n",
    "gs.score(X_train, y_train)\n",
    "gs.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "svc = svm.SVC(C = 100,\n",
    "              kernel = 'rbf',\n",
    "              gamma = 0.0001)\n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model.\n",
    "accuracy_score(y_test, svc.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
